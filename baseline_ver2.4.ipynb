{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"5K7uCCiufz7B"},"source":["# Import"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T08:04:16.886478Z","iopub.status.busy":"2023-07-18T08:04:16.885525Z","iopub.status.idle":"2023-07-18T08:04:21.406063Z","shell.execute_reply":"2023-07-18T08:04:21.405083Z","shell.execute_reply.started":"2023-07-18T08:04:16.886425Z"},"id":"i9zIjTGkfz7D","trusted":true},"outputs":[],"source":["import os\n","import cv2\n","import pandas as pd\n","import numpy as np\n","import random\n","from typing import List, Union\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","import torch.nn.functional as F\n","from sklearn.model_selection import KFold\n","\n","from tqdm import tqdm\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","import datetime\n","import pytz\n","import matplotlib.pyplot as plt\n","\n","import utils\n","import model"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"3Ooxc4Uqfz7D"},"source":["# Config"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T08:08:24.593732Z","iopub.status.busy":"2023-07-18T08:08:24.593025Z","iopub.status.idle":"2023-07-18T08:08:24.604475Z","shell.execute_reply":"2023-07-18T08:08:24.603505Z","shell.execute_reply.started":"2023-07-18T08:08:24.593695Z"},"id":"UHYuB9Vgfz7E","trusted":true},"outputs":[],"source":["config = {\n","    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n","    'data_path': 'train1000', # change relative path of data -> ex) kaggle: '/kaggle/input/swdacon', colab: '/content/drive/MyDrive/open'\n","    'save_path': 'result', # change relative path where result is stored -> ex) kaggle: '/kaggle/working/', colab: '/content/drive/MyDrive/open'\n","    'train_data': 'train_1000.csv', # change train data csv name\n","    'test_data': 'test_20.csv', # change test data csv name\n","    'seed': 42,\n","    'valid_size': 0.1,\n","    'early_stopping': 30,\n","    'scheduler': True,\n","    'nums_pixel': False,\n","    'k-fold': 1, # 1이하의 정수이면 사용하지 않음\n","    'train' : {\n","       'batch_size' : 16,\n","       'num_workers': 1,\n","       'epochs': 200,\n","       'lr': 0.001,\n","    },\n","    'inference' : {\n","       'batch_size' : 8,\n","       'num_workers': 1,\n","       'threshold': 0.35,\n","    },\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if not os.path.exists(config['save_path']):\n","    os.makedirs(config['save_path'])\n","    print(\"save path가 생성되었습니다.\")\n","print(\"save_path:\", os.path.abspath(config['save_path']))\n","if not os.path.exists(config['data_path']):\n","    raise FileNotFoundError(\"base path가 존재하지 않습니다. 데이터가 있는 경로를 확인해주세요.\")\n","else:\n","    print(\"data_path:\", os.path.abspath(config['data_path']))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"SHwprIlKfz7F"},"source":["# Train\n","- 1024 * 1024 * 3 이미지 학습"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"CDaRUHiefz7F"},"source":["### load train data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T08:12:49.644818Z","iopub.status.busy":"2023-07-18T08:12:49.644434Z","iopub.status.idle":"2023-07-18T08:12:49.649863Z","shell.execute_reply":"2023-07-18T08:12:49.648630Z","shell.execute_reply.started":"2023-07-18T08:12:49.644790Z"},"id":"4TiZngGjfz7G","trusted":true},"outputs":[],"source":["train_df = pd.read_csv(f\"{config['data_path']}/{config['train_data']}\")\n","train_df['img_path'] = config['data_path'] + train_df['img_path'].str[1:]\n","if config['k-fold'] > 1:\n","    kfold = KFold(n_splits=config['k-fold'], random_state=config['seed'], shuffle=True)\n","    print(kfold)\n","else:\n","    train, val = train_test_split(train_df, test_size=config['valid_size'], random_state=config['seed'])\n","    print(\"train: \", len(train), \"   valid: \", len(val))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"rr3JXa-Rfz7G"},"source":["### Custom Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T08:12:51.651987Z","iopub.status.busy":"2023-07-18T08:12:51.651611Z","iopub.status.idle":"2023-07-18T08:12:51.661843Z","shell.execute_reply":"2023-07-18T08:12:51.660654Z","shell.execute_reply.started":"2023-07-18T08:12:51.651958Z"},"id":"ncKvptxvfz7H","trusted":true},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, img_paths, mask_rles = None, transform=None, infer=False):\n","        self.img_paths = img_paths\n","        self.mask_rles = mask_rles\n","        self.transform = transform\n","        self.infer = infer\n","\n","    def __len__(self):\n","        return len(self.img_paths)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.img_paths.iloc[idx]\n","        image = cv2.imread(img_path)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","        if self.infer:\n","            if self.transform:\n","                image = self.transform(image=image)['image']\n","            return image\n","\n","        mask_rle = self.mask_rles.iloc[idx]\n","        mask = utils.rle_decode(mask_rle, (image.shape[0], image.shape[1]))\n","\n","        if self.transform:\n","            augmented = self.transform(image=image, mask=mask)\n","            image = augmented['image']\n","            mask = augmented['mask']\n","\n","        return image, mask"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"uMN0PGY2fz7H"},"source":["### Data Loader"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-07-18T08:12:54.835340Z","iopub.status.busy":"2023-07-18T08:12:54.834887Z","iopub.status.idle":"2023-07-18T08:12:54.843449Z","shell.execute_reply":"2023-07-18T08:12:54.842452Z","shell.execute_reply.started":"2023-07-18T08:12:54.835302Z"},"id":"yqlN9fQGfz7H","outputId":"82fd7cb8-438c-4183-e5f5-717eeaf3f763","trusted":true},"outputs":[],"source":["utils.fix_seed(config['seed'])\n","\n","if config['k-fold'] > 1:\n","    print(f\"k-fold: {config['k-fold']} 입력되어, training할 때 fold별 dataloader가 생성됩니다.\")\n","else:\n","    train_dataset = CustomDataset(img_paths=train['img_path'], mask_rles=train['mask_rle'], transform=utils.base_transform['train'])\n","    train_dataloader = DataLoader(train_dataset, batch_size=config['train']['batch_size'], shuffle=True)\n","\n","    valid_dataset = CustomDataset(img_paths=val['img_path'], mask_rles=val['mask_rle'], transform=utils.base_transform['valid'])\n","    valid_dataloader = DataLoader(valid_dataset , batch_size=config['train']['batch_size'], shuffle=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"h5Voy5Jyfz7H"},"source":["### Model\n","- default: smp unet"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Load model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-07-18T08:13:00.706595Z","iopub.status.busy":"2023-07-18T08:13:00.706221Z","iopub.status.idle":"2023-07-18T08:13:00.712961Z","shell.execute_reply":"2023-07-18T08:13:00.711847Z","shell.execute_reply.started":"2023-07-18T08:13:00.706568Z"},"id":"VVb65UMvfz7I","outputId":"957b309d-148a-4076-d5dd-aa20f6b376e5","trusted":true},"outputs":[],"source":["if config['k-fold'] > 1:\n","    print(f\"k-fold: {config['k-fold']} 입력되어, training할 때 fold별 model이 생성됩니다.\")\n","else:\n","    model = model.SMP() # 사용할 모델 선택\n","    model = model.load_models(\"UNet\")\n","    temp_model = model"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"46kfdtYXfz7I"},"source":["### Validation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T08:13:02.402926Z","iopub.status.busy":"2023-07-18T08:13:02.402546Z","iopub.status.idle":"2023-07-18T08:13:02.415901Z","shell.execute_reply":"2023-07-18T08:13:02.414576Z","shell.execute_reply.started":"2023-07-18T08:13:02.402898Z"},"id":"Nka7W0Z1fz7I","trusted":true},"outputs":[],"source":["def validation(config, model, criterion, valid_loader, val):\n","    model.eval()\n","    valid_loss = 0\n","    result = []\n","    transformed_mask = []\n","    val_df = val.copy()\n","\n","    with torch.no_grad():\n","        for images, masks in tqdm(valid_loader):\n","            if type(transformed_mask) == torch.Tensor:\n","                transformed_mask = torch.cat([transformed_mask, masks])\n","            else:\n","                transformed_mask = masks.clone().detach()\n","            images = images.float().to(config['device'])\n","            masks = masks.float().to(config['device'])\n","\n","            outputs = model(images)\n","            loss = criterion(outputs, masks.unsqueeze(1))\n","            valid_loss += loss.item()\n","\n","            output_masks = torch.sigmoid(outputs).cpu().numpy()\n","            output_masks = np.squeeze(output_masks, axis=1)\n","            output_masks = (output_masks > config['inference']['threshold']).astype(np.uint8)\n","\n","            for i in range(len(images)):\n","                mask_rle = utils.rle_encode(output_masks[i])\n","                if mask_rle == '': # 예측된 건물 픽셀이 아예 없는 경우 -1\n","                    result.append(-1)\n","                else:\n","                    result.append(mask_rle)\n","        val_df['valid_mask_rle'] = result\n","        val_df['transformed_mask_rle'] = list(map(utils.rle_encode, transformed_mask.squeeze().numpy()))\n","        dice_score = utils.calculate_dice_scores(val_df)\n","        if config['nums_pixel']:\n","            mean_error_ratio, more_pred, less_pred = utils.calculate_nums_pixel(val_df)\n","    if config['nums_pixel']:\n","        return valid_loss/len(valid_loader), dice_score, mean_error_ratio, more_pred, less_pred\n","    else:\n","        return valid_loss/len(valid_loader), dice_score"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"31hn_PvNfz7I"},"source":["### Train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T08:13:04.083691Z","iopub.status.busy":"2023-07-18T08:13:04.083337Z","iopub.status.idle":"2023-07-18T08:13:04.101673Z","shell.execute_reply":"2023-07-18T08:13:04.100633Z","shell.execute_reply.started":"2023-07-18T08:13:04.083663Z"},"id":"tVn0bgodfz7J","trusted":true},"outputs":[],"source":["def training(config, model, train_loader, valid_loader, val, fold=0):\n","    device = config['device']\n","    model = model.to(device)\n","    es_count = 0\n","    min_val_loss = float('inf')\n","    best_model = None\n","\n","    criterion = torch.nn.BCEWithLogitsLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=config['train']['lr'])\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-8, verbose=True)\n","    print(\"***TRAINING START***\")\n","    # training loop\n","    for epoch in range(config['train']['epochs']):\n","        model.train()\n","        epoch_loss = 0\n","        for images, masks in tqdm(train_loader):\n","            images = images.float().to(config['device'])\n","            masks = masks.float().to(config['device'])\n","\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, masks.unsqueeze(1))\n","            loss.backward()\n","            optimizer.step()\n","\n","            epoch_loss += loss.item()\n","\n","        if config['nums_pixel']:\n","            val_loss, dice_score, mean_error_ratio, more_pred, less_pred  = validation(config, model, criterion, valid_loader, val)\n","        else:\n","            val_loss, dice_score = validation(config, model, criterion, valid_loader, val)\n","\n","        es_count += 1\n","        if min_val_loss > val_loss:\n","            es_count = 0\n","            min_val_loss = val_loss\n","            best_model = model\n","            state_dict = model.state_dict()\n","            best_epoch = epoch + 1\n","            print(f\"Epoch [{epoch + 1}] New Minimum Valid Loss!\")\n","            if epoch+1 > 50: # 비정상적인 종료에 대비해 몇 epoch 이상부터 저장할지 결정합니다.\n","                if fold:\n","                    current_model = f\"fold{fold}_current_best_model.pt\"\n","                else:\n","                    current_model = \"current_best_model.pt\"\n","                print(\"..save current best model..\")\n","                torch.save(state_dict, f'{config[\"save_path\"]}/{current_model}')\n","\n","        if config['scheduler']:\n","            scheduler.step(val_loss)\n","\n","        if es_count == config['early_stopping']:\n","            if config['nums_pixel']:\n","                print(f'Epoch {epoch+1}, Train Loss: {(epoch_loss/len(train_loader)):6f}, Valid Loss: {val_loss:6f}, ES Count: {es_count}')\n","                print(f'Dice Coefficient: {dice_score:6f}, (GT - Pred)/GT: {mean_error_ratio:2f}, More Pred : Less Pred = {more_pred} : {less_pred}')\n","            else:\n","                print(f'Epoch {epoch+1}, Train Loss: {(epoch_loss/len(train_loader)):6f}, Valid Loss: {val_loss:6f}, Dice Coefficient: {dice_score:6f}, ES Count: {es_count}')\n","            print(f\"Early Stopping Count에 도달했습니다! \\nEarly Stopping Count: {config['early_stopping']} Best Epoch: {best_epoch}\")\n","            print(\"***TRAINING DONE***\")\n","            return best_model, state_dict\n","\n","        if config['nums_pixel']:\n","            print(f'Epoch {epoch+1}, Train Loss: {(epoch_loss/len(train_loader)):6f}, Valid Loss: {val_loss:6f}, ES Count: {es_count}')\n","            print(f'Dice Coefficient: {dice_score:6f}, (GT - Pred)/GT: {mean_error_ratio:2f}, More Pred : Less Pred = {more_pred} : {less_pred}')\n","        else:\n","            print(f'Epoch {epoch+1}, Train Loss: {(epoch_loss/len(train_loader)):6f}, Valid Loss: {val_loss:6f}, Dice Coefficient: {dice_score:6f}, ES Count: {es_count}')\n","        print(\"------------------------------------------------------------------------------------\")\n","\n","    print(f\"Early Stopping Count에 도달하지 않았습니다! \\nEarly Stopping Count: {config['early_stopping']} Best Epoch: {best_epoch}\")\n","    print(\"***TRAINING DONE***\")\n","    return best_model, state_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-07-18T08:13:06.363028Z","iopub.status.busy":"2023-07-18T08:13:06.362671Z","iopub.status.idle":"2023-07-18T08:13:06.370348Z","shell.execute_reply":"2023-07-18T08:13:06.369355Z","shell.execute_reply.started":"2023-07-18T08:13:06.363000Z"},"id":"iWEOtbSafz7J","outputId":"f7730c55-d719-4e4d-afea-1901a58c5468","trusted":true},"outputs":[],"source":["torch.cuda.is_available() # 학습 전에 GPU 쓰고 있나 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-07-18T08:14:14.373190Z","iopub.status.busy":"2023-07-18T08:14:14.372807Z","iopub.status.idle":"2023-07-18T08:14:28.036387Z","shell.execute_reply":"2023-07-18T08:14:28.035409Z","shell.execute_reply.started":"2023-07-18T08:14:14.373152Z"},"id":"TjqWUMZHfz7J","outputId":"0135c701-bea9-4f07-dd24-5f72e9b9c9e2","trusted":true},"outputs":[],"source":["utils.fix_seed(config['seed'])\n","\n","if config['k-fold'] > 1:\n","    best_models, best_model_state_dicts = [], []\n","    for i, (train_idx, val_idx) in enumerate(kfold.split(train_df)):\n","        train = train_df.iloc[train_idx,:]\n","        val = train_df.iloc[val_idx,:]\n","        train_dataset = CustomDataset(img_paths=train['img_path'], mask_rles=train['mask_rle'], transform=custom_transform['train'])\n","        train_dataloader = DataLoader(train_dataset, batch_size=config['train']['batch_size'], shuffle=True)\n","\n","        valid_dataset = CustomDataset(img_paths=val['img_path'], mask_rles=val['mask_rle'], transform=custom_transform['valid'])\n","        valid_dataloader = DataLoader(valid_dataset , batch_size=config['train']['batch_size'], shuffle=False)\n","        print(f\"--- Start Fold {i + 1} ---\")\n","        model = model.SMP() # 사용할 모델 선택\n","        model = model.load_models(\"UNet\")\n","        temp_model = model\n","        best_model, best_model_state_dict = training(config, model, train_dataloader, valid_dataloader, val, i+1)\n","        best_models.append(best_model)\n","        best_model_state_dicts.append(best_model)\n","        print(f\"---- End Fold {i + 1} ----\")\n","else:\n","    best_model, best_model_state_dict = training(config, model, train_dataloader, valid_dataloader, val)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"LhyW_vXZfz7J"},"source":["## Inference\n","- 224 * 224 * 3 이미지 추론"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"9MhxeH3Jfz7J"},"source":["### load test data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lm36r_M6fz7K"},"outputs":[],"source":["test_df = pd.read_csv(f\"{config['data_path']}/{config['test_data']}\")\n","test_df['img_path'] = config['data_path'] + test_df['img_path'].str[1:]"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"08fx1Xpbfz7K"},"source":["### Data Loader"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2023-07-18T08:15:42.203102Z","iopub.status.busy":"2023-07-18T08:15:42.202738Z","iopub.status.idle":"2023-07-18T08:15:42.210766Z","shell.execute_reply":"2023-07-18T08:15:42.209602Z","shell.execute_reply.started":"2023-07-18T08:15:42.203073Z"},"id":"nFARP8g6fz7K","outputId":"2588c259-6d5e-46d5-d1d0-1ffbb0182b85","trusted":true},"outputs":[],"source":["utils.fix_seed(config['seed'])\n","\n","if config['k-fold'] > 1:\n","    print(f\"k-fold: {config['k-fold']} 입력되어, inference할 때 fold별 dataloader가 생성됩니다.\")\n","else:\n","    test_dataset = CustomDataset(img_paths=test_df['img_path'], transform=utils.base_transform['test'], infer=True)\n","    test_dataloader = DataLoader(test_dataset, batch_size=config['inference']['batch_size'], shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T08:15:46.346512Z","iopub.status.busy":"2023-07-18T08:15:46.346114Z","iopub.status.idle":"2023-07-18T08:15:46.355413Z","shell.execute_reply":"2023-07-18T08:15:46.354340Z","shell.execute_reply.started":"2023-07-18T08:15:46.346483Z"},"id":"sirK1vZnfz7K","trusted":true},"outputs":[],"source":["def inference(config, model, test_loader):\n","    with torch.no_grad():\n","        model.eval()\n","        result = []\n","        for images in tqdm(test_loader):\n","            images = images.float().to(config['device'])\n","\n","            outputs = model(images)\n","            masks = torch.sigmoid(outputs).cpu().numpy()\n","            masks = np.squeeze(masks, axis=1)\n","            masks = (masks > config['inference']['threshold']).astype(np.uint8)\n","\n","            for i in range(len(images)):\n","                mask_rle = utils.rle_encode(masks[i])\n","                if mask_rle == '': # 예측된 건물 픽셀이 아예 없는 경우 -1\n","                    result.append(-1)\n","                else:\n","                    result.append(mask_rle)\n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":248},"execution":{"iopub.execute_input":"2023-07-18T08:15:58.326855Z","iopub.status.busy":"2023-07-18T08:15:58.326477Z","iopub.status.idle":"2023-07-18T08:15:59.768505Z","shell.execute_reply":"2023-07-18T08:15:59.767545Z","shell.execute_reply.started":"2023-07-18T08:15:58.326827Z"},"id":"CEf27eQefz7K","outputId":"189e5999-7bf6-4cc0-c63f-2f3a774d87c9","trusted":true},"outputs":[],"source":["if config['k-fold'] > 1:\n","    inference_results = []\n","    for i, fold_model in enumerate(best_models):\n","        test_dataset = CustomDataset(img_paths=test_df['img_path'], transform=utils.base_transform['test'], infer=True)\n","        test_dataloader = DataLoader(test_dataset, batch_size=config['inference']['batch_size'], shuffle=False)\n","        print(f\"--- Start Fold {i + 1} ---\")\n","        inference_result = inference(config, fold_model, test_dataloader)\n","        inference_results.append(inference_result)\n","else:\n","    inference_result = inference(config, best_model, test_dataloader)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"S_KhxIOwfz7K"},"source":["## Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hg33PZevfz7Q"},"outputs":[],"source":["kst = pytz.timezone('Asia/Seoul')\n","now = datetime.datetime.now(tz=kst)\n","current_time = now.strftime(\"%y%m%d-%H_%M_%S\")\n","\n","if config['k-fold'] > 1:\n","    for i,inference_result in enumerate(inference_results):\n","        submit = pd.read_csv(f\"{config['data_path']}/sample_submission.csv\")\n","        submit['mask_rle'] = inference_result\n","        file_name = f\"fold_{i+1}_{current_time}.csv\"\n","        submit.to_csv(f\"{config['save_path']}/{file_name}\", index=False)\n","\n","    # 모델 저장\n","    for i,best_model_state_dict in enumerate(best_model_state_dicts):\n","        model_name = f\"fold_{i+1}_{current_time}.pt\"\n","        torch.save(best_model, f\"{config['data_path']}/{model_name}\")\n","else:\n","    submit = pd.read_csv(f\"{config['data_path']}/sample_submission.csv\")\n","    submit['mask_rle'] = inference_result\n","    file_name = f\"{current_time}.csv\"\n","    submit.to_csv(f\"{config['save_path']}/{file_name}\", index=False)\n","\n","    # 모델 저장\n","    model_name = f\"{current_time}.pt\"\n","    torch.save(best_model, f\"{config['save_path']}/{model_name}\")\n","print(file_name)\n","print(model_name)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"m3fVWItmfz7Q"},"source":["# Submission Viewer\n","- fold 사용시엔 사용할 필요 x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-18T08:26:29.327051Z","iopub.status.busy":"2023-07-18T08:26:29.326629Z","iopub.status.idle":"2023-07-18T08:26:29.335304Z","shell.execute_reply":"2023-07-18T08:26:29.334265Z","shell.execute_reply.started":"2023-07-18T08:26:29.327020Z"},"id":"DZAesskGfz7Q","trusted":true},"outputs":[],"source":["def submission_viewer(test_csv, submit_csv, img_num):\n","    \"\"\"\n","    white -> 건물 black -> 배경\n","    1. Local에서 사용 시 test_csv, submit_csv, img_num만 입력\n","    2. colab에서 사용 시 아래 사항을 입력\n","    base_path = colab_base\n","    is_colab = True\n","    \"\"\"\n","    mask_rle = submit_csv.iloc[img_num, 1]\n","    image_path = test_csv.iloc[img_num, 1]\n","    image = cv2.imread(image_path)\n","    mask = rle_decode(mask_rle, (image.shape[0], image.shape[1]))\n","    fig = plt.figure()\n","    ax1 = fig.add_subplot(1,2,1)\n","    ax1.imshow(image)\n","    ax1.set_title('image')\n","    ax2 = fig.add_subplot(1,2,2)\n","    ax2.imshow(mask,cmap='gray')\n","    ax2.set_title('mask')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GCRdr-zgfz7R"},"outputs":[],"source":["if config['k-fold'] > 1:\n","    print(\"Ensemble을 진행하십시오.\")\n","else:\n","    last_submit = pd.read_csv(f\"{config['save_path']}/{file_name}\")\n","    submission_viewer(test_df, last_submit, 0)\n","    submission_viewer(test_df, last_submit, 1)\n","    submission_viewer(test_df, last_submit, 2)"]},{"cell_type":"markdown","metadata":{},"source":["# inference 확인"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 모델 불러와 파라미터 입력\n","temp_model.load_state_dict(torch.load('/home/kimyw/SWdacon2/SWdacon/open/fold1_epoch227_current_model.pt')) # pt 파일 경로 설정\n","# eval 모드\n","temp_model = temp_model.eval()\n","# GPU로 옮기기\n","temp_model = temp_model.to(config['device'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","pred_dataset = CustomDataset(img_paths=train_df['img_path'], transform=utils.base_transform['valid'], infer=True)\n","pred_dataloader = DataLoader(pred_dataset, batch_size=config['inference']['batch_size'], shuffle=False)\n","inference_result = inference(config, temp_model, pred_dataloader)\n","\n","K = A.augmentations.crops.transforms.CenterCrop(224,224,p=1.0)\n","\n","submit = pd.DataFrame({ 'mask_rle' : inference_result})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 예측 결과 뷰어\n","def pred_viewer(train_df, valid_csv, img_num):\n","    \"\"\"\n","    white -> 건물 black -> 배경\n","    1. Local에서 사용 시 train_df, pred_csv, img_num만 입력\n","    2. colab에서 사용 시 아래 사항을 입력\n","    data_path = colab_base\n","    is_colab = True\n","    \"\"\"\n","    mask_rle = train_df.iloc[img_num, 2]\n","    image_path = train_df.iloc[img_num, 1]\n","    pred = valid_csv.iloc[img_num, 0]\n","\n","    image = cv2.imread(image_path)\n","    image=K(image=image)['image']\n","    mask = utils.rle_decode(mask_rle, (1024, 1024))\n","    mask=K(image=mask)['image']\n","    pred = utils.rle_decode(pred, (224, 224))\n","    \n","    fig = plt.figure()\n","    ax1 = fig.add_subplot(1,3,1)\n","    ax1.imshow(image)\n","    ax1.set_title('image')\n","    ax2 = fig.add_subplot(1,3,2)\n","    ax2.imshow(pred,cmap='gray')\n","    ax2.set_title('pred_mask')\n","    ax3 = fig.add_subplot(1,3,3)\n","    ax3.imshow(mask,cmap='gray')\n","    ax3.set_title('gt_mask')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pred_viewer(train_df, submit, 18)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.17"}},"nbformat":4,"nbformat_minor":4}
